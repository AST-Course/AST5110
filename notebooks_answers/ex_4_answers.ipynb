{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Stabilities and accuracy in time\n",
    "\n",
    "_As the wave speed used for calculating time step is the maximum wave speed at each time step, which would be constant for all grid points, we first use a constant $C^n$ to replace $u^n_j$ in the second term of the right hand side, without changing the stability_\n",
    "$$u^{n+1}_j = \\frac{1}{2}(u^n_{j+1} + u^n_{j-1}) - \\frac{C^n \\Delta t}{2 \\Delta x}(u^n_{j+1} - u^n_{j-1})$$\n",
    "_Then von Neumann stability analysis of the Lax method is written below_\n",
    "\n",
    "$$\\xi^{n+1}e^{ikj\\Delta x} = \\frac{1}{2}(\\xi^n e^{ik(j+1)\\Delta x} + \\xi^n e^{ik(j-1)\\Delta x}) - \\frac{C^n \\Delta t}{2 \\Delta x}(\\xi^ne^{ik(j+1)\\Delta x} - \\xi^ne^{ik(j-1)\\Delta x})$$\n",
    "$$ = \\frac{1}{2}(\\xi^n e^{ikj\\Delta x}e^{ik\\Delta x} + \\xi^n e^{ikj\\Delta x}/e^{ik\\Delta x}) - \\frac{C^n\\Delta t}{2 \\Delta x}(\\xi^ne^{ikj\\Delta x}e^{ik\\Delta x} - \\xi^ne^{ikj\\Delta x}/e^{ik\\Delta x})$$\n",
    "$$ = \\xi^n e^{ikj\\Delta x}[\\frac{1}{2}(e^{ik\\Delta x} + 1/e^{ik\\Delta x}) - \\frac{C^n\\Delta t}{2 \\Delta x}(e^{ik\\Delta x} - 1/e^{ik\\Delta x})]$$\n",
    "$$ = \\xi^n e^{ikj\\Delta x}[\\cos({k\\Delta x})-\\frac{iC^n\\Delta t}{\\Delta x}\\sin({k\\Delta x})]$$\n",
    "\n",
    "_where $\\xi^{n}e^{ikj\\Delta x}$ is one of the terms in the fourier expansion of the round-off error at step $n$ and grid point $j$. Given $A=\\cos({k\\Delta x})-\\frac{iC^n\\Delta t}{\\Delta x}\\sin({k\\Delta x})$, we calculate (the square of) the absolute value of the complex number_ $A$\n",
    "$$|A|^2= \\cos^2({k\\Delta x})+\\left(\\frac{C^n\\Delta t}{\\Delta x}\\right)^2\\sin^2({k\\Delta x})$$\n",
    "$$= 1-\\sin^2({k\\Delta x})+\\left(\\frac{C^n\\Delta t}{\\Delta x}\\right)^2\\sin^2({k\\Delta x})$$\n",
    "$$= 1-\\left[1-\\left(\\frac{C^n\\Delta t}{\\Delta x}\\right)^2\\right]\\sin^2({k\\Delta x})$$\n",
    "_Therefore, to have $|A|^2\\le 1$, we need $\\left[1-\\left(\\frac{C^n\\Delta t}{\\Delta x}\\right)^2\\right]\\ge 0$, i.e., $\\frac{C^n\\Delta t}{\\Delta x}\\le 1$, where $C^n$ is in fact the allowed CFL number._\n",
    "\n",
    "_From the results shown below, we find that at $t\\approx 25$, the difference between the total computing times (but the same number of time steps and same CFL) of the Lax method and the backward differencing method is $<10^{-4}$ (due to the slight difference between the maximum speeds). However, the difference between the locations of the wave fronts of two numerical results is already $>0.2$, which means the difference between two propagation speeds is several orders of magnetide higher than the one expected while assuming the same propagation speed. This is due to the fact that the wave speed in front of the pulse is zero, and thus the du is always zero in front of the pulse._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os   \n",
    "sys.path.append(os.getcwd()+'/..')\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import nm_lib as nm\n",
    "from typing import Type\n",
    "from matplotlib import animation \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "# --- Values reused in other tasks of ex_3 ---\n",
    "x0 = -1.4 \n",
    "xf = 2.0\n",
    "xc = 0.7\n",
    "W = 0.1\n",
    "pi = math.pi\n",
    "CFL = 0.98\n",
    "A = 0.02\n",
    "# ---------------------------\n",
    "\n",
    "def tfunc_Burgers(xx, A, B):\n",
    "    return A * (math.tanh((xx + xc) / W) - math.tanh((xx - xc) / W)) + B\n",
    "\n",
    "def discretisation(x0, xf, nump, dt_float: Type[float]):\n",
    "    nint = nump - 1\n",
    "    dh = dt_float((xf - x0) / nint)\n",
    "    xx = dt_float(np.arange(nump) * dh + x0) \n",
    "    xx_half = dt_float(np.arange(nump) * dh + x0 + dh * 0.5)\n",
    "    return nint, dh, xx, xx_half\n",
    "\n",
    "def run_Burgers(nump, nt, CFL, A, B, ddx1 = lambda x,y: nm.deriv_cent(x,y), ddx2 = lambda x,y: nm.deriv_bck(x,y), bnd_limits: list=[1,1],):\n",
    "    nint, dh, xx, xx_half = discretisation(x0, xf, nump, dt_float=np.float64)\n",
    "\n",
    "    hh = np.zeros(nump)\n",
    "    for i in range(0, nump):\n",
    "        hh[i] = tfunc_Burgers(xx[i], A, B)\n",
    " \n",
    "    t1, unnt1 = nm.evolv_Lax_uadv_burgers(xx, hh, nt, CFL, ddx1, 'wrap', bnd_limits)\n",
    "    t2, unnt2 = nm.evolv_uadv_burgers(xx, hh, nt, CFL, ddx2, 'wrap', bnd_limits)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.xlim(xx[0], xx[nump-1])\n",
    "    plt.ylim(unnt1[:,0].min() - 0.1 * (unnt1[:,0].max() - unnt1[:,0].min()), unnt1[:,0].max() + 0.1 * (unnt1[:,0].max() - unnt1[:,0].min()))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"u\") \n",
    "    line1, = plt.plot([], [], '--', label='Lax solution')\n",
    "    line2, = plt.plot([], [], '--', label='Backward differencing solution') \n",
    "\n",
    "    plt.legend(loc='lower right') \n",
    "    time_text1 = plt.text(0.02, 0.95, '', transform=plt.gca().transAxes)\n",
    "    time_text2 = plt.text(0.02, 0.95, '', transform=plt.gca().transAxes)\n",
    " \n",
    "    def init():\n",
    "        line1.set_data([], [])\n",
    "        line2.set_data([], [])\n",
    "        time_text1.set_text('')\n",
    "        time_text2.set_text('')\n",
    "        return line1, line2\n",
    " \n",
    "    def update(frame):\n",
    "        line1.set_data(xx, unnt1[:,frame])  \n",
    "        line2.set_data(xx, unnt2[:,frame]) \n",
    "        time_text1.set_text(\"Time1 = \"+str(t1[frame]))\n",
    "        time_text2.set_text(\"Time2 = \"+str(t2[frame]))\n",
    "        return line1, line2\n",
    " \n",
    "    anim = animation.FuncAnimation(plt.gcf(), update, init_func=init, frames=t1.size-1, blit=True)\n",
    "    plt.show(block=True)\n",
    "\n",
    "nump = 65   \n",
    "nt = 21\n",
    "B = 0.0\n",
    "run_Burgers(nump, nt, CFL, A, B)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Diffusive\n",
    "\n",
    "_First we complete the formula above by writing it as the combination of two different orders of derivatives_\n",
    "$$(u^{n+1}_j - u^{n}_j) / {\\Delta t} = \\frac{1}{2}(u^n_{j+1} + u^n_{j-1}) / {\\Delta t} - (u^{n}_j) / {\\Delta t} - \\frac{u^n_{j}}{2 \\Delta x}(u^n_{j+1} - u^n_{j-1}) $$\n",
    "$$ = \\frac{1}{2}(u^n_{j+1} - 2u^n_{j} + u^n_{j-1}) / {\\Delta t} - \\frac{u^n_{j}}{2 \\Delta x}(u^n_{j+1} - u^n_{j-1})$$\n",
    "$$ = \\frac{1}{2}[(u^n_{j+1} - u^n_{j}) - (u^n_{j} - u^n_{j-1})] / {\\Delta t} - \\frac{u^n_{j}}{2 \\Delta x}(u^n_{j+1} - u^n_{j-1})$$\n",
    "$$ = \\frac{\\Delta^2 x}{2 \\Delta^2 x\\Delta t}[(u^n_{j+1} - u^n_{j}) - (u^n_{j} - u^n_{j-1})] - \\frac{u^n_{j}}{2 \\Delta x}(u^n_{j+1} - u^n_{j-1})$$\n",
    "_So for the whole computational domain, where the maximum wave speed is used to calculate the time step, we have_\n",
    "$$u^{n+1}=u^{n} - \\frac{\\Delta t}{2\\Delta x}u^n_{j}(u^n_{j+1} - u^n_{j-1})+ \\frac{{\\Delta^2 t}}{2{\\Delta^2 x}} {\\max}^2(u^n)[(u^n_{j+1} - u^n_{j}) - (u^n_{j} - u^n_{j-1})]$$\n",
    "_The formula above can be rewritten as_ \n",
    "$$u^{n+1}=u^{n} - \\frac{\\Delta t}{2}u^n_{j}\\left(\\frac{\\partial u}{\\partial x}\\right)_j+\\frac{{\\Delta^2 t}}{2} {\\max}^2(u^n)\\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)_j$$\n",
    "_As the second term on the right hand side is actually a diffusive term, it leads to strong diffusion when the __maximum speed__ is large. Moreover, the ratio between the second and first order derivatives are related also related to the time step._\n",
    "\n",
    "_The results below show that the Lax method is more diffusive than the backward diferencing method, especially when the CFL is relatively small. However, the test below also shows that the Lax method should be second-order accurate, which means that its error decreases faster than the backward difference when finer meshes are used._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of accuracy of the Lax method is 2.293374537005224\n",
      "The order of accuracy of the backward difference is 0.9795337285066997\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#nt = 100\n",
    "#CFL=0.98\n",
    "#B = 0.0\n",
    "#nump = 257\n",
    "#run_Burgers(nump, nt, CFL, A, B) \n",
    "#nt = 200\n",
    "#CFL=0.98\n",
    "#B = 0.3\n",
    "#nump = 257\n",
    "#run_Burgers(nump, nt, CFL, A, B)    \n",
    "#nt = 400\n",
    "#CFL=0.49\n",
    "#B = 0.3\n",
    "#nump = 257\n",
    "#run_Burgers(nump, nt, CFL, A, B) \n",
    "#nt = 800\n",
    "#CFL=0.49\n",
    "#B = 0.3\n",
    "#nump = 513\n",
    "#run_Burgers(nump, nt, CFL, A, B) \n",
    "\n",
    "x0 = -2.6 \n",
    "xf = 2.6 \n",
    "\n",
    "def tfunc(xx):\n",
    "    return math.cos(6.0 * pi * xx / 5.0) * math.cos(6.0 * pi * xx / 5.0) /  math.cosh(5.0 * xx * xx)\n",
    "\n",
    "def order_Burgers(nt, CFL, ddx1 = lambda x,y: nm.deriv_cent(x,y), ddx2 = lambda x,y: nm.deriv_bck(x,y), bnd_limits: list=[1,1],):\n",
    "    nump1 = 65\n",
    "    nint1, dh1, xx1, xx_half1 = discretisation(x0, xf, nump1, dt_float=np.float64)\n",
    "\n",
    "    hh1 = np.zeros(nump1)\n",
    "    for i in range(0, nump1):\n",
    "        hh1[i] = tfunc(xx1[i])\n",
    " \n",
    "    t11, unnt11 = nm.evolv_Lax_uadv_burgers(xx1, hh1, nt, CFL, ddx1, 'wrap', bnd_limits)\n",
    "    t12, unnt12 = nm.evolv_uadv_burgers(xx1, hh1, nt, CFL, ddx2, 'wrap', bnd_limits)\n",
    "\n",
    "    nump2 = 129\n",
    "    nint2, dh2, xx2, xx_half2 = discretisation(x0, xf, nump2, dt_float=np.float64)\n",
    "\n",
    "    hh2 = np.zeros(nump2)\n",
    "    for i in range(0, nump2):\n",
    "        hh2[i] = tfunc(xx2[i])\n",
    " \n",
    "    t21, unnt21 = nm.evolv_Lax_uadv_burgers(xx2, hh2, nt*2, CFL, ddx1, 'wrap', bnd_limits)\n",
    "    t22, unnt22 = nm.evolv_uadv_burgers(xx2, hh2, nt*2, CFL, ddx2, 'wrap', bnd_limits)\n",
    "\n",
    "    nump3 = 257\n",
    "    nint3, dh3, xx3, xx_half3 = discretisation(x0, xf, nump3, dt_float=np.float64)\n",
    "\n",
    "    hh3 = np.zeros(nump3)\n",
    "    for i in range(0, nump3):\n",
    "        hh3[i] = tfunc(xx3[i])\n",
    " \n",
    "    t31, unnt31 = nm.evolv_Lax_uadv_burgers(xx3, hh3, nt*4, CFL, ddx1, 'wrap', bnd_limits)\n",
    "    t32, unnt32 = nm.evolv_uadv_burgers(xx3, hh3, nt*4, CFL, ddx2, 'wrap', bnd_limits)\n",
    "\n",
    "    print(\"The order of accuracy of the Lax method is\", nm.order_conv(unnt11[:,nt-1], unnt21[:,nt*2-1], unnt31[:,nt*4-1]))\n",
    "    print(\"The order of accuracy of the backward difference is\", nm.order_conv(unnt12[:,nt-1], unnt22[:,nt*2-1], unnt32[:,nt*4-1]))\n",
    "\n",
    "nt = 15\n",
    "CFL = 0.9 \n",
    "order_Burgers(nt, CFL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ast5110_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
